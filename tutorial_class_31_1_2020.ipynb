{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'realiz'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer #importing PorterStemmer as sp\n",
    "sp=PorterStemmer()\n",
    "sp.stem(\"realization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'realizabilti'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.stem(\"realizabilty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'irrationaliz'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.stem(\"irrationalizability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lie'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.stem(\"lying\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stealer'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sp.stem(\"stealer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'undi'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.stem(\"undying\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'undy'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import LancasterStemmer #importing Lancaster Stemmer as l\n",
    "l=LancasterStemmer()\n",
    "l.stem(\"undying\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'real'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.stem(\"realization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'realizabil'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.stem(\"realizabilty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lying'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.stem(\"Lying\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('arabic', 'danish', 'dutch', 'english', 'finnish', 'french', 'german', 'hungarian', 'italian', 'norwegian', 'porter', 'portuguese', 'romanian', 'russian', 'spanish', 'swedish')\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer #importing Snowball Stemmer as snow\n",
    "print(SnowballStemmer.languages)\n",
    "snow=SnowballStemmer(\"danish\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'irrationaliz'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snow=SnowballStemmer(\"english\")\n",
    "snow.stem(\"irrationalizability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'realize'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snow.stem(\"Realization\") #Snowball stemmer stems it better than Porter or Lancaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "realiz\n",
      "real\n"
     ]
    }
   ],
   "source": [
    "print(snow.stem(\"Realizability\")) #Lancaster stemmer works better than Snowball\n",
    "print(l.stem(\"realizability\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'undi'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snow.stem(\"Undying\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i need toothbrushes that costs less than $2'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snow.stem(\"I  $2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "be\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemm=WordNetLemmatizer()\n",
    "print(lemm.lemmatize(\"am\", pos='v'))        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lovely\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "print(lemm.lemmatize(\"lovelier\", wordnet.ADJ))        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unentitled\n"
     ]
    }
   ],
   "source": [
    "print(lemm.lemmatize(\"unentitled\", wordnet.NOUN))        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Am quick brown fox jump over a lazi dog\n"
     ]
    }
   ],
   "source": [
    "eg=\"Am quick brown fox jumps over a lazy dog\"\n",
    "eg=[sp.stem(token) for token in eg.split()]\n",
    "print(\" \".join(eg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Am quick brown fox jump over a lazy dog\n"
     ]
    }
   ],
   "source": [
    "eg=\"Am quick brown fox jumps over a lazy dog\"\n",
    "eg=[lemm.lemmatize(token) for token in eg.split()]\n",
    "print(\" \".join(eg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-42-05f41c645586>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-42-05f41c645586>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    WordSim ws = new WordSim(representation);\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "representation = \"esa\";\n",
    "WordSim ws = new WordSim(representation);\n",
    "ws.compare(\"word\", \"sentence\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mass'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import RegexpStemmer  #creating our personalized regexp stremmer\n",
    "st = RegexpStemmer('ing$|s$|e$|able$|alization$|ive$|ic$|ize$|ian$|x$', min=4)\n",
    "st.stem(\"massive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'massiv'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snow.stem(\"massive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mass'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.stem(\"massive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nation'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.stem(\"nationalization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nation'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snow.stem(\"nationalization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'unrecogniz'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snow.stem(\"unrecognizable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'unrecogniz'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.stem(\"unrecognizable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'unrecogn'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.stem(\"unrecognizable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neurot'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snow.stem(\"neurotic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'idol'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snow.stem(\"idolize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'idol'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.stem(\"idolize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "electrician\n",
      "elect\n"
     ]
    }
   ],
   "source": [
    "print(snow.stem(\"electrician\"))\n",
    "print(l.stem(\"electrician\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "electric\n",
      "electrician\n"
     ]
    }
   ],
   "source": [
    "print(st.stem(\"electrician\"))\n",
    "print(sp.stem(\"Electrician\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'milieux'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f=SnowballStemmer(\"french\")\n",
    "f.stem(\"milieux\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'milieux'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snow=SnowballStemmer(\"english\")\n",
    "snow.stem(\"milieux\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'milieux'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.stem(\"milieux\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'milieu'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.stem(\"milieux\")#milieux is the plural form of milieu, so RegExp performs better than Snowball, Lancaster and Porter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'milieux'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.stem(\"milieux\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('happy.a.01'),\n",
       " Synset('felicitous.s.02'),\n",
       " Synset('glad.s.02'),\n",
       " Synset('happy.s.04')]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('happy', pos=wn.ADJ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-87-b5d61008fa94>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msynset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"dog\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\wordnet.py\u001b[0m in \u001b[0;36msynset\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1327\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msynset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1328\u001b[0m         \u001b[1;31m# split name into lemma, part of speech and synset number\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1329\u001b[1;33m         \u001b[0mlemma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msynset_index_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrsplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1330\u001b[0m         \u001b[0msynset_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msynset_index_str\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 1)"
     ]
    }
   ],
   "source": [
    "dog=wn.synset(\"dog\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('breathe.v.01')\n",
      "Synset('respire.v.02')\n",
      "Synset('respire.v.01')\n",
      "Synset('choke.v.01')\n",
      "Synset('hyperventilate.v.02')\n",
      "Synset('hyperventilate.v.01')\n",
      "Synset('aspirate.v.03')\n",
      "Synset('burp.v.01')\n",
      "Synset('force_out.v.08')\n",
      "Synset('hiccup.v.01')\n",
      "Synset('sigh.v.01')\n",
      "Synset('exhale.v.01')\n",
      "Synset('hold.v.36')\n",
      "Synset('exhale.v.02')\n",
      "Synset('sneeze.v.01')\n",
      "Synset('inhale.v.02')\n",
      "Synset('pant.v.01')\n",
      "Synset('cough.v.01')\n",
      "Synset('hack.v.08')\n",
      "Synset('expectorate.v.02')\n",
      "Synset('snort.v.02')\n",
      "Synset('wheeze.v.01')\n",
      "Synset('puff.v.08')\n",
      "Synset('blow.v.01')\n",
      "Synset('insufflate.v.03')\n",
      "Synset('yawn.v.01')\n",
      "Synset('sniff.v.02')\n",
      "Synset('blink.v.01')\n",
      "Synset('palpebrate.v.01')\n",
      "Synset('bat.v.02')\n",
      "Synset('wink.v.01')\n",
      "Synset('wink.v.04')\n",
      "Synset('squint.v.01')\n",
      "Synset('squint.v.03')\n",
      "Synset('wince.v.02')\n",
      "Synset('shed.v.04')\n",
      "Synset('desquamate.v.01')\n",
      "Synset('twitch.v.01')\n",
      "Synset('fibrillate.v.01')\n",
      "Synset('move_involuntarily.v.01')\n",
      "Synset('act_involuntarily.v.01')\n",
      "Synset('act.v.02')\n",
      "Synset('fall_over_backwards.v.01')\n",
      "Synset('presume.v.04')\n",
      "Synset('vulgarize.v.03')\n",
      "Synset('optimize.v.03')\n",
      "Synset('quack.v.02')\n",
      "Synset('menace.v.03')\n",
      "Synset('make.v.19')\n",
      "Synset('swagger.v.03')\n",
      "Synset('freeze.v.10')\n",
      "Synset('wanton.v.06')\n",
      "Synset('romanticize.v.03')\n",
      "Synset('sentimentalise.v.03')\n",
      "Synset('bungle.v.02')\n",
      "Synset('play.v.16')\n",
      "Synset('act.v.05')\n",
      "Synset('stooge.v.03')\n",
      "Synset('shake.v.02')\n",
      "Synset('shiver.v.02')\n",
      "Synset('rest.v.05')\n",
      "Synset('be_active.v.01')\n",
      "Synset('sleep.v.01')\n",
      "Synset('bundle.v.04')\n",
      "Synset('snooze.v.01')\n",
      "Synset('nap.v.01')\n",
      "Synset('oversleep.v.01')\n",
      "Synset('sleep_late.v.01')\n",
      "Synset('hibernate.v.01')\n",
      "Synset('estivate.v.01')\n",
      "Synset('drowse.v.02')\n",
      "Synset('nod.v.05')\n",
      "Synset('nod.v.03')\n",
      "Synset('zonk_out.v.02')\n",
      "Synset('snore.v.01')\n",
      "Synset('fall_asleep.v.01')\n",
      "Synset('bed_down.v.01')\n",
      "Synset('doss.v.01')\n",
      "Synset('go_to_bed.v.01')\n",
      "Synset('get_up.v.02')\n",
      "Synset('get_up.v.04')\n",
      "Synset('wake_up.v.02')\n",
      "Synset('awaken.v.01')\n",
      "Synset('reawaken.v.01')\n",
      "Synset('cause_to_sleep.v.01')\n",
      "Synset('affect.v.02')\n",
      "Synset('attack.v.06')\n",
      "Synset('ulcerate.v.02')\n",
      "Synset('wake.v.01')\n",
      "Synset('stay_up.v.01')\n",
      "Synset('keep_up.v.05')\n",
      "Synset('hypnotize.v.01')\n",
      "Synset('entrance.v.02')\n",
      "Synset('anesthetize.v.01')\n",
      "Synset('etherize.v.01')\n",
      "Synset('cocainize.v.01')\n",
      "Synset('chloroform.v.01')\n",
      "Synset('freeze.v.09')\n",
      "Synset('bring_to.v.01')\n",
      "Synset('sedate.v.01')\n"
     ]
    }
   ],
   "source": [
    ">>> for synset in list(wn.all_synsets('v'))[:100]:  #finding first 100 synset words of verb form\n",
    "    print(synset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('choke.v.01').path_similarity(wn.synset('breathe.v.01'))#finding similarity between words \"choke\" and \"breathe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
